{"meta":{"title":"ye's blog","subtitle":"","description":"","author":"Ye","url":"https://Bayeeaa.github.io","root":"/"},"pages":[{"title":"about","date":"2023-08-22T07:06:19.000Z","updated":"2023-08-22T07:07:20.142Z","comments":false,"path":"about/index.html","permalink":"https://bayeeaa.github.io/about/index.html","excerpt":"","text":"hello!"}],"posts":[{"title":"爬虫 --- 以爬取笔趣阁小说为例","slug":"biquge","date":"2023-08-31T07:40:23.000Z","updated":"2023-09-10T08:32:08.483Z","comments":true,"path":"2023/08/31/biquge/","link":"","permalink":"https://bayeeaa.github.io/2023/08/31/biquge/","excerpt":"","text":"爬虫 — 以爬取笔趣阁小说为例1.发送请求123456import requestsurl = &quot;https://www.xzmncy.com/list/5418/2610707.html&quot;headers = &#123; &quot;User-Agent&quot; : &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0&quot;&#125;response = requests.get(url,headers) 这是requests请求，若返回response值为200，则表示请求成功 2.获取数据1response = requests.get(url,headers).text 可以通过以上方法返回得到的html文件内容，而文件中有很多标签在里面，不能直接获取想要的信息，所以需要数据解析 3.解析数据有以下几种途径：css、xpath、re正则表达 等等 让我们来看看分别用这三种方法怎么去解析到一个章节的标题 css123import parselselector = parsel.Selector(response)novel_title = selector.css(&quot;.bookname h1::text&quot;).get() 这种方法通过css选择器进行选择 xpath123import parselselector = parsel.Selector(response)novel_title = selector.xpath(&quot;//*[@class=&quot;bookname&quot;]/h1/text()&quot;).get() 注意text后面的() re12import renovel_title = re.findall(&quot;&lt;h1&gt;(.*?)&lt;/h1&gt;&quot;,response)[0] 这里是因为h1在html文件中只有一个，故我直接导入。获取的数据是一个列表，所以我后面做了个且切片来直接获取字符串 *注意：以上方法各有利弊，选择合适的方式来解析数据 4.保存数据12with open(&quot;file_name&quot;+&quot;.txt&quot;,mode=&quot;w&quot;,encoding=&quot;utf-8&quot;) as f: #w是写入但是覆盖，a是追加写入，写入文件末尾 wb是二进制写入f.write(novel_context) #写入文件 with open(download_path,mode&#x3D;””,encoding&#x3D;”utf-8”)中间的download_path可以写绝对路径 以上思路已经理清楚了，下面开始实践：爬取一章12345678910111213import parselimport requestsurl = &quot;https://www.xzmncy.com/list/5418/2610707.html&quot;headers = &#123; &quot;User-Agent&quot; : &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0&quot;&#125;response = requests.get(url,headers).textselector = parsel.Selector(response)novel_title = selector.css(&quot;.bookname h1::text&quot;).get() #css方法解析数据novel_context_list = selector.css(&quot;#htmlContent p::text&quot;).getall() novel_context = &quot;\\n&quot;.join(novel_context_list) 注意：join函数的使用： 123456a=[&quot;1&quot;,&quot;2&quot;,&quot;8&quot;,&quot;9&quot;]print(&quot; &quot;.join(a)) #输出1 2 8 9print(&quot;\\n&quot;.join(a)) #输出1(换行)2(换行)8(换行)9b=&#123;&quot;a&quot;:1,&quot;b&quot;:2&#125;print(&quot; &quot;.join(a)) #输出a b （注意seq不能是int整形） 爬取各章url12345678910111213import requestsimport reurl = &quot;https://www.xzmncy.com/list/18753/&quot;headers = &#123; &quot;User-Agent&quot; : &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0&quot; &#125;response = requests.get(url,headers).textnovel_name = re.findall(&quot;&lt;h1&gt;(.*?)&lt;/h1&gt;&quot;,response)[0]novel_info = re.findall(&#x27;&lt;dd&gt;&lt;a href=&quot;(.*?)&quot;&gt;(.*?)&lt;/a&gt;&lt;/dd&gt;&#x27;,response)for novel_url_part,novel_title in novel_info: novel_url = &quot;https://www.xzmncy.com&quot;+novel_url_part[0:24] print(novel_url) print(novel_title) 在小说的列表页面我们可以发现每个标签对应的章节url，此时我们获取的数据是这样的： 我们就可以用re来解析到各个章节的url和title 完整代码123456789101112131415161718192021222324import requestsimport reimport parselurl = &quot;https://www.xzmncy.com/list/18753/&quot;headers = &#123; &quot;User-Agent&quot; : &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0&quot; &#125;response = requests.get(url,headers).textnovel_name = re.findall(&quot;&lt;h1&gt;(.*?)&lt;/h1&gt;&quot;,response)[0]novel_info = re.findall(&#x27;&lt;dd&gt;&lt;a href=&quot;(.*?)&quot;&gt;(.*?)&lt;/a&gt;&lt;/dd&gt;&#x27;,response)for novel_url_part,novel_title in novel_info: novel_url = &quot;https://www.xzmncy.com&quot;+novel_url_part[0:24] novel_response = requests.get(novel_url, headers).text selectors = parsel.Selector(novel_response) novel_context_list = selectors.css(&quot;#htmlContent p::text&quot;).getall() novel_context = &quot;\\n&quot;.join(novel_context_list) print(&quot;正在保存&quot;+novel_title) novel_title = &quot;*&quot; + novel_title with open(novel_name+&quot;.txt&quot;,mode=&quot;a&quot;) as f: f.write(novel_title) f.write(&quot;\\n&quot;) f.write(novel_context) f.write(&quot;\\n&quot;) f.write(&quot;\\n&quot;) 运行代码就可以看到当前的目录下出现一个txt文件，里面就是想要的小说啦~","categories":[],"tags":[]},{"title":"CSS选择器","slug":"css选择器","date":"2023-08-23T04:35:42.000Z","updated":"2023-08-24T07:48:46.105Z","comments":true,"path":"2023/08/23/css选择器/","link":"","permalink":"https://bayeeaa.github.io/2023/08/23/css%E9%80%89%E6%8B%A9%E5%99%A8/","excerpt":"","text":"引入方式引入方式有以下三种： 1.内嵌式 12345678910111213&lt;!-- 内嵌式 --&gt;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; colour&#123; colour:pink; &#125; &lt;/style&gt;&lt;/head&gt; 2.外联式 12345678910&lt;!-- 外联式 --&gt;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;./111.css&quot;&gt; &lt;!-- 111为引入文件名 --&gt;&lt;/head&gt; 3.行内式 1234567&lt;!-- 行内式 --&gt;&lt;body&gt; &lt;div class=&quot;colour&quot;&gt; abcd &lt;/div&gt; &lt;div style=&quot;color: aqua;font-size: large;&quot;&gt;abab&lt;/div&gt;&lt;/body&gt; 选择器一共有4种：标签选择器、类选择器、id选择器、通符选择器 注：一下选择器均是在style标签下的 1.标签123div&#123; color:blue;&#125; 所选类型与body中html的文本类型相符(如上文中，其下文body中应该是div) 2.类选择器123.color-choose&#123; color:blue;&#125; 其html调用方式为： 1&lt;div class=&quot;color-choose&quot;&gt; abab &lt;/div&gt; 3.id选择器123#color&#123; color:blue;&#125; 其html调用方式为： 1&lt;div id=&quot;color&quot;&gt; abab &lt;/div&gt; 注意：id只得调用一次 4.通符选择器12345*&#123; margin:0; padding:0;&#125;&lt;!-- 清除内外边距 --&gt; 对全局内容生效 选择器的选择1.后代 （后面所有代）问题如下 1234&lt;p&gt; abab &lt;/p&gt;&lt;div&gt; &lt;p&gt; 哈哈哈 &lt;/p&gt;&lt;/div&gt; 欲选择div中的p标签，而不是外部的p 以如下方法实现： 12345&lt;style&gt; div p &#123; color:blue; &#125;&lt;/style&gt; 2.子代 （后面一代）问题是要选中div后面的一代 123456&lt;div&gt; &lt;p&gt; dd &lt;/p&gt; &lt;p&gt; &lt;a href=&quot;#&quot;&gt; ddd &lt;/a&gt; &lt;/p&gt;&lt;/div&gt; 以如下方法实现： 123div&gt;p&#123; color:blue;&#125; 3.并集问题：想要让以下这些标签被选到 1234&lt;p&gt; p &lt;/p&gt;&lt;div&gt; div &lt;/div&gt;&lt;span&gt; span &lt;/span&gt;&lt;h1&gt; haha &lt;/h1&gt; 以下面方法实现： 123p,div,span,h1&#123; color:blue;&#125; 4.交集问题：只想要选中下面p中带class&#x3D;”c”的 1234&lt;div class=&quot;c&quot;&gt;abcd&lt;/div&gt;&lt;p class=&quot;c&quot;&gt;a&lt;/p&gt;&lt;div class=&quot;c&quot;&gt;d&lt;/div&gt;&lt;p class=&quot;c&quot;&gt;b&lt;/p&gt; 以下面方法实现： 123p.c&#123; color:blue;&#125; p是标签，c是类名（前面带个.的） 5.伪类问题：想要让鼠标悬停在如下超链接上能够变色 1&lt;a href=&quot;~~~&quot;&gt;传送&lt;/a&gt; 一下方法实现： 1234a:hover&#123; color:red; background-color:yellow;&#125;","categories":[],"tags":[]},{"title":"破壳啦","slug":"page1","date":"2023-08-21T11:25:42.000Z","updated":"2023-08-22T13:45:57.473Z","comments":true,"path":"2023/08/21/page1/","link":"","permalink":"https://bayeeaa.github.io/2023/08/21/page1/","excerpt":"","text":"终于创建好一个博客啦！","categories":[],"tags":[]}],"categories":[],"tags":[]}